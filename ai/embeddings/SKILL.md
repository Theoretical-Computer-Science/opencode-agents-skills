# Embeddings

Embeddings are dense vector representations of text, images, or other data that capture semantic meaning. They're the foundation of semantic search and RAG applications.

## Key Concepts

- Text embeddings (text-embedding-ada-002, e5, bge)
- Image embeddings (CLIP, ResNet)
- Dimensionality reduction
- Similarity computation
- Batch processing

## Common Use Cases

- Semantic search
- Text classification
- Clustering
- Duplicate detection
- RAG systems

## Best Practices

- Choose model based on use case
- Normalize vectors for cosine similarity
- Handle long texts with chunking
- Cache embeddings when possible
- Monitor embedding drift

## Resources

- OpenAI Embeddings, Hugging Face, Cohere
- Related Skills: vector-databases, nlp, machine-learning
